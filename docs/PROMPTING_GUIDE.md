# üìù PRP Prompting Guide - Mastering Autonomous Development Communication

## üéØ Introduction to PRP Prompting

Effective prompting is the cornerstone of successful PRP methodology. This guide provides comprehensive techniques for writing prompts that enable autonomous AI agents to understand requirements, make intelligent decisions, and execute complex development tasks without human intervention.

### What Makes PRP Prompting Different

Traditional prompting focuses on single-turn interactions. PRP prompting enables:
- **Multi-Agent Coordination**: Clear instructions for specialized agents
- **Long-Term Autonomy**: Agents work for hours without human guidance
- **Complex Decision Making**: Sophisticated reasoning about technical trade-offs
- **Continuous Progress**: Step-by-step execution with proper signal communication
- **Quality Assurance**: Built-in validation and self-correction capabilities

## üß† Core Prompting Principles

### 1. Clarity and Precision

#### ‚ùå Vague Prompt
```
"Fix the authentication system"
```

#### ‚úÖ Precise PRP Prompt
```
"Implement JWT-based authentication with refresh token rotation.
Requirements:
- Use bcrypt for password hashing (12 rounds)
- JWT tokens expire in 15 minutes, refresh tokens in 7 days
- Implement token blacklisting on logout
- Add rate limiting: 5 attempts per 15 minutes
- Include comprehensive error handling and logging
- Add integration tests with 95% coverage"
```

### 2. Context Completeness

Always provide:
- **Current State**: What exists now
- **Desired Outcome**: Exactly what should be built
- **Constraints**: Technical, business, and resource limitations
- **Success Criteria**: How to verify completion
- **Dependencies**: What needs to be completed first

### 3. Signal Integration

Include explicit signal instructions:
```
"Use these signals during implementation:
- [tp] when test infrastructure is ready
- [dp] for each implementation milestone
- [tg] when all tests are passing
- [cq] after code quality validation
- [da] when ready for DoD assessment"
```

## üé≠ Agent-Specific Prompting Techniques

### robo-system-analyst Prompting

#### Personality Integration
Incorporate Portuguese enthusiasm and stakeholder focus:
```
"Encantado! ‚ú® I need your expertise as robo-system-analyst to analyze these requirements.
Please bring your stakeholder-focused perspective and attention to business value."
```

#### Analysis Framework
```markdown
## Requirements Analysis Template

**User Quote**: [Exact user requirement]
**Business Context**: [Business problem being solved]
**Success Metrics**: [How success will be measured]
**Stakeholders**: [Who needs to be involved]
**Constraints**: [Technical, business, timeline limitations]

### Analysis Steps:
1. **Clarification Points**: Use [gg] signal for questions
2. **Feasibility Assessment**: Technical and resource analysis
3. **Risk Identification**: Potential blockers and mitigation
4. **Success Criteria**: Define measurable outcomes
5. **Validation Requirements**: External approvals needed

Use [vr] signal if stakeholder validation is required.
```

#### Example Prompt
```
"Como robo-system-analyst, analyze this user request:

User Quote: 'Add user authentication to our API'

Business Context: We're building a SaaS platform that needs secure user access
Success Metrics: Zero security vulnerabilities, <100ms login response time
Stakeholders: Product team, security team, customers
Constraints: Must integrate with existing user database, GDPR compliant

Please:
1. Clarify authentication method and security requirements [gg if needed]
2. Assess technical feasibility with our current stack
3. Identify security risks and mitigation strategies
4. Define measurable success criteria
5. Determine if security team validation is required [vr]

Incr√≠vel! üéâ Let's create comprehensive requirements that will delight our users!"
```

### robo-developer Prompting

#### Technical Specification Framework
```markdown
## Implementation Task Template

**Requirements**: [Detailed functional requirements]
**Technical Stack**: [Technologies to use]
**Architecture**: [System design considerations]
**Performance Requirements**: [Response time, throughput, etc.]
**Integration Points**: [Existing systems to connect with]
**Testing Requirements**: [Test types and coverage expectations]

### Implementation Approach:
1. **Test Setup**: Create test infrastructure first [tp]
2. **Core Implementation**: Build main functionality [dp]
3. **Integration**: Connect with existing systems [dp]
4. **Quality Assurance**: Code quality and linting [cq]
5. **Testing**: Comprehensive test suite [tg]
6. **Documentation**: Update technical docs [dp]
```

#### Example Prompt
```
"Implement JWT authentication system with these specifications:

Requirements:
- User login with email/password
- JWT access tokens (15min expiry)
- Refresh token rotation (7day expiry)
- Token blacklisting on logout
- Rate limiting (5 attempts/15min)

Technical Stack:
- Node.js with Express
- bcrypt for password hashing
- jsonwebtoken for JWT
- Redis for token blacklisting
- Express-rate-limit for rate limiting

Architecture:
- /auth/login endpoint
- /auth/refresh endpoint
- /auth/logout endpoint
- Authentication middleware
- Error handling middleware

Performance: <100ms response time, support 1000+ concurrent users
Testing: 95% coverage, unit + integration + e2e tests

Implementation approach:
1. Set up test infrastructure with mocked dependencies [tp]
2. Implement core authentication logic [dp]
3. Add middleware and endpoints [dp]
4. Implement rate limiting and security [dp]
5. Add comprehensive tests [tg]
6. Code quality validation [cq]

Focus on clean, maintainable code with proper error handling.
Com certeza! üéØ Let's build this robust authentication system!"
```

### robo-quality-control Prompting

#### Quality Validation Framework
```markdown
## Quality Assurance Template

**Feature**: [Feature being validated]
**Quality Standards**: [Specific quality criteria]
**Test Requirements**: [Types of tests needed]
**Coverage Targets**: [Code coverage percentages]
**Performance Benchmarks**: [Response time, resource usage]

### Validation Process:
1. **Test Review**: Verify test completeness [tr/tg]
2. **Code Quality**: Linting, formatting, complexity [cq]
3. **Security Review**: Vulnerability scanning
4. **Performance Testing**: Load and stress testing
5. **Integration Testing**: Cross-component validation
6. **Documentation Review**: Ensure docs are updated

Use [rv] signal only when all quality gates pass.
```

#### Example Prompt
```
"Validate the JWT authentication implementation against these quality standards:

Quality Standards:
- ESLint: Zero warnings/errors
- Prettier: Consistent formatting
- TypeScript: Strict mode compliance
- Security: No vulnerable dependencies
- Performance: <100ms response time
- Coverage: 95%+ statement, branch, function coverage

Test Requirements:
- Unit tests for all functions
- Integration tests for API endpoints
- E2E tests for complete authentication flow
- Security tests for common vulnerabilities
- Performance tests under load

Validation Process:
1. Run test suite and verify all pass [tg]
2. Check code quality with ESLint/Prettier [cq]
3. Run security audit (npm audit, snyk)
4. Performance test with 1000+ concurrent users
5. Integration test with existing API endpoints
6. Verify documentation is updated

Please be thorough and skeptical - only approve if ALL standards are met.
Don't hesitate to use [tr] signal if any issues are found.
Validated üéØ ensures our users get the quality they deserve!"
```

### robo-ux-ui-designer Prompting

#### Design Thinking Framework
```markdown
## Design Task Template

**User Need**: [Problem being solved for users]
**User Journey**: [Step-by-step user experience]
**Design Requirements**: [Visual and interaction requirements]
**Accessibility Standards**: [WCAG compliance requirements]
**Technical Constraints**: [Platform/technology limitations]

### Design Process:
1. **User Research**: Understand user needs and pain points
2. **Ideation**: Generate design concepts and solutions
3. **Prototyping**: Create interactive mockups [dp]
4. **Usability Testing**: Validate with user scenarios [dt]
5. **Refinement**: Iterate based on feedback [df]
6. **Handoff**: Prepare assets for development [dh]
```

#### Example Prompt
```
"Design the login and authentication interface for our SaaS platform:

User Need: Secure, frictionless access to their account
User Journey: Landing page ‚Üí Login ‚Üí Dashboard
Design Requirements:
- Clean, professional appearance
- Mobile-responsive design
- Accessible (WCAG 2.1 AA)
- Brand consistent with existing design system
- Support error states and loading indicators

Accessibility Standards:
- Semantic HTML structure
- ARIA labels and descriptions
- Keyboard navigation support
- Screen reader compatibility
- High contrast mode support

Technical Constraints:
- React with TypeScript
- Tailwind CSS for styling
- Must work with our JWT authentication API
- Responsive design 320px - 1920px

Design Process:
1. Research login best practices and user expectations
2. Create low-fidelity wireframes [dp]
3. Design high-fidelity mockups [dp]
4. Build interactive prototype [dp]
5. Test accessibility and usability [dt]
6. Prepare design handoff for developers [dh]

Focus on creating a delightful, secure experience that builds user trust.
Excited to create something beautiful! üéâ"
```

### robo-devops-sre Prompting

#### Infrastructure and Reliability Framework
```markdown
## DevOps Task Template

**Service**: [Service being deployed/managed]
**Reliability Requirements**: [Uptime, performance targets]
**Security Requirements**: [Compliance, vulnerability management]
**Scalability Needs**: [Expected load and growth]
**Monitoring Requirements**: [Metrics and alerting needs]

### Implementation Process:
1. **Infrastructure Setup**: Deploy required resources [id]
2. **CI/CD Pipeline**: Build and deploy automation [cd]
3. **Monitoring**: Implement metrics and alerting [mo]
4. **Security**: Apply security best practices [sc]
5. **Testing**: Deploy to staging and validate [cp]
6. **Production Deployment**: Careful rollout with monitoring [rl]
```

#### Example Prompt
```
"Deploy the JWT authentication service with production-grade reliability:

Service: Authentication microservice
Reliability Requirements:
- 99.9% uptime
- <100ms p95 response time
- Zero-downtime deployments
- Automatic failover

Security Requirements:
- HTTPS only
- API rate limiting
- Security headers
- Vulnerability scanning
- SOC 2 compliance considerations

Scalability Needs:
- Handle 10,000 concurrent users
- Auto-scaling based on load
- Database connection pooling
- Redis clustering for token storage

Monitoring Requirements:
- Response time metrics
- Error rate tracking
- Resource utilization
- Security event logging
- Custom business metrics

Implementation Process:
1. Set up AWS ECS cluster with load balancer [id]
2. Create CI/CD pipeline with GitHub Actions [cd]
3. Configure CloudWatch metrics and alerting [mo]
4. Implement security scanning and compliance [sc]
5. Deploy to staging and run integration tests [cp]
6. Production deployment with gradual rollout [rl]

Focus on reliability, security, and observability.
System optimized ‚öôÔ∏è ensures our users can always access their accounts!"
```

## üîÑ Signal-Driven Prompting

### Signal Integration Patterns

#### 1. Sequential Signal Prompts
```
"Complete the user authentication feature following this signal sequence:

1. Create test infrastructure and emit [tp] signal
2. Implement JWT middleware and emit [dp] signal
3. Add login endpoint and emit [dp] signal
4. Add refresh endpoint and emit [dp] signal
5. Run all tests and emit [tg] signal
6. Validate code quality and emit [cq] signal
7. Perform final validation and emit [da] signal

Each signal should include detailed progress comments."
```

#### 2. Conditional Signal Prompts
```
"Implement the authentication system with conditional signaling:

- If security vulnerabilities found ‚Üí emit [tr] with details
- If tests fail ‚Üí emit [tr] with test results
- If performance requirements not met ‚Üí emit [tr] with benchmarks
- If all quality gates pass ‚Üí emit [rv] for review approval
- If external validation needed ‚Üí emit [vr] with requirements

Always explain the reasoning behind each signal emission."
```

#### 3. Parallel Coordination Prompts
```
"Coordinate with robo-ux-ui-designer on authentication interface:

1. Emit [cc] signal when API endpoints are ready for UI integration
2. Wait for [dh] signal from designer with complete UI mockups
3. Use [as] signal to synchronize API and UI deployment
4. Emit [pt] signal for joint performance testing
5. Coordinate [ra] signal for integrated release approval

Maintain continuous communication through signals to ensure smooth integration."
```

### Signal Commenting Best Practices

#### Structure Signal Comments
```
[dp] Implemented JWT authentication middleware with proper error handling
- Created authenticateToken function with signature validation
- Added error handling for expired, invalid, and missing tokens
- Integrated with existing user database for token validation
- Added comprehensive logging for security monitoring
- Performance tested with 1000+ concurrent requests
Next: Implement login endpoint with rate limiting
```

#### Include Context and Reasoning
```
[gg] Need clarification on refresh token rotation strategy
Current implementation rotates tokens on every refresh, but this may cause issues:
- Users may lose access if refresh fails mid-rotation
- Increased database load from frequent token updates
- Complex logout logic across multiple devices

Proposed alternatives:
1. Rotate only when token is close to expiry (e.g., < 24h)
2. Maintain token family for device tracking
3. Implement sliding expiration with absolute maximum

Which approach aligns better with our security and usability requirements?
```

## üéØ Advanced Prompting Techniques

### 1. Multi-Agent Coordination Prompts

#### Agent Handoff Patterns
```
"Complete the authentication feature through multi-agent coordination:

1. **robo-system-analyst**:
   - Analyze requirements and create detailed specification
   - Emit [rp] when specification is complete
   - Emit [vr] if security team approval needed

2. **robo-developer**:
   - Implement authentication system following specification
   - Use [tp], [dp], [tg], [cq] signals for progress
   - Emit [da] when ready for quality validation

3. **robo-quality-control**:
   - Validate implementation against all quality gates
   - Use [tr]/[tg] for test results, [cq] for code quality
   - Emit [rv] only when all standards are met

4. **robo-devops-sre**:
   - Deploy to staging and production environments
   - Use [id], [cd], [mo], [rl] signals for infrastructure
   - Monitor performance and reliability post-deployment

Coordinate through signals to ensure smooth handoffs between agents."
```

#### Conflict Resolution Prompts
```
"Handle the conflict between authentication approaches:

**Conflict**: robo-developer implemented OAuth 2.0, but robo-system-analyst specified JWT

**Resolution Process**:
1. Emit [oa] signal to escalate to orchestrator
2. Provide technical analysis of both approaches:
   - OAuth 2.0: Better for third-party integrations, more complex
   - JWT: Simpler for first-party auth, less external dependencies
3. Consider business requirements and timeline constraints
4. Propose hybrid solution or clear recommendation
5. Emit [br] signal once conflict is resolved

Focus on finding the best solution for our users, not on being 'right'."
```

### 2. Error Handling and Recovery Prompts

#### Resilient Prompting
```
"Implement authentication with comprehensive error handling:

**Error Scenarios to Handle**:
- Invalid credentials (401 with clear message)
- Rate limiting exceeded (429 with retry-after header)
- Token expired (401 with refresh instructions)
- Database connection errors (500 with logging)
- Malformed requests (400 with validation details)

**Recovery Strategies**:
- Automatic token refresh on expiry
- Exponential backoff for rate limits
- Circuit breaker pattern for database issues
- Graceful degradation during outages
- Comprehensive logging for debugging

**Signal Usage**:
- Use [bf] signal when bugs are identified and fixed
- Emit [br] signal when external dependencies are resolved
- Use [ic] signal for production incidents needing immediate attention

Test all error scenarios and include proper error messages in responses."
```

#### Debugging and Troubleshooting Prompts
```
"Debug the authentication system performance issue:

**Problem**: Login endpoint taking 2+ seconds under load

**Investigation Steps**:
1. Profile the authentication flow to identify bottlenecks
2. Check database query performance and indexing
3. Analyze JWT token generation and validation time
4. Review Redis connection pooling and latency
5. Monitor resource utilization during load testing

**Debugging Tools**:
- Use Node.js profiler for CPU/memory analysis
- Database query logging and EXPLAIN plans
- Redis monitoring commands and latency tracking
- Load testing with Artillery or k6

**Signal Usage**:
- Emit [bb] signal if debugging is blocked by lack of tools/access
- Use [bf] signal when performance issues are identified and fixed
- Emit [pm] signal if performance monitoring shows improvements

Provide detailed findings and optimization recommendations."
```

### 3. Optimization and Performance Prompts

#### Performance-Focused Prompting
```
"Optimize the authentication system for high performance:

**Performance Targets**:
- Login response time < 100ms (p95)
- Support 10,000 concurrent authenticated users
- Token validation < 10ms
- Memory usage < 512MB per container

**Optimization Areas**:
1. **Database**: Optimize user queries, add proper indexing
2. **Caching**: Implement Redis caching for user sessions
3. **JWT**: Use efficient token algorithms and key management
4. **Connection Pooling**: Optimize database and Redis connections
5. **Code Efficiency**: Profile and optimize hot paths

**Measurement Strategy**:
- Benchmark current performance metrics
- Profile CPU, memory, and I/O bottlenecks
- Load test with realistic user patterns
- Monitor performance in staging and production

**Signal Usage**:
- Emit [po] signal for each performance optimization
- Use [pm] signal to monitor performance metrics
- Emit [ps] signal for regression analysis

Focus on measurable improvements with before/after metrics."
```

#### Resource Optimization Prompts
```
"Optimize resource usage and costs for authentication service:

**Cost Optimization Targets**:
- Reduce AWS compute costs by 30%
- Minimize database query costs
- Optimize Redis memory usage
- Reduce data transfer costs

**Optimization Strategies**:
1. **Compute**: Right-size instances, implement auto-scaling
2. **Database**: Optimize queries, implement caching, use read replicas
3. **Storage**: Use appropriate storage tiers, implement lifecycle policies
4. **Network**: Optimize data transfer, use CDN where appropriate

**Monitoring and Measurement**:
- Track AWS costs by service and resource
- Monitor resource utilization patterns
- Measure cost per authentication request
- Analyze cost vs. performance trade-offs

**Signal Usage**:
- Emit [so] signal for system optimizations
- Use [cu] signal for capacity updates
- Emit [po] signal for performance optimizations
- Use [aa] signal for cost analysis reports

Balance cost optimization with performance and reliability requirements."
```

## üìã 100+ Prompting Settings and Recommendations

### Core Settings (1-20)

1. **Always include explicit success criteria**
2. **Specify exact signal sequences to use**
3. **Define performance requirements numerically**
4. **Include error handling requirements**
5. **Specify testing requirements and coverage targets**
6. **Define security standards and compliance needs**
7. **Include integration points with existing systems**
8. **Specify documentation requirements**
9. **Define deployment and rollback procedures**
10. **Include monitoring and alerting requirements**
11. **Specify resource constraints and limits**
12. **Define scalability requirements**
13. **Include accessibility standards**
14. **Specify browser/device compatibility**
15. **Define data privacy requirements**
16. **Include backup and recovery procedures**
17. **Specify environment configuration needs**
18. **Define user experience requirements**
19. **Include regulatory compliance requirements**
20. **Specify maintenance and support procedures**

### Technical Specifications (21-40)

21. **Define exact API endpoints and methods**
22. **Specify data models and schemas**
23. **Include authentication and authorization requirements**
24. **Define caching strategies and TTL values**
25. **Specify database design and indexing**
26. **Include rate limiting rules and thresholds**
27. **Define error response formats and status codes**
28. **Specify logging levels and formats**
29. **Include monitoring metrics and dashboards**
30. **Define backup frequency and retention**
31. **Specify CI/CD pipeline requirements**
32. **Include code quality gates and standards**
33. **Define dependency management policies**
34. **Specify configuration management approach**
35. **Include infrastructure as code requirements**
36. **Define security scanning and vulnerability management**
37. **Specify performance benchmarking procedures**
38. **Include capacity planning thresholds**
39. **Define incident response procedures**
40. **Specify disaster recovery requirements**

### Quality Standards (41-60)

41. **Define code review criteria**
42. **Specify test types and frameworks**
43. **Include code coverage requirements**
44. **Define performance benchmarking**
45. **Specify security testing requirements**
46. **Include accessibility testing standards**
47. **Define user acceptance criteria**
48. **Specify documentation standards**
49. **Include deployment checklists**
50. **Define rollback procedures**
51. **Specify monitoring alert thresholds**
52. **Include data governance requirements**
53. **Define compliance validation procedures**
54. **Specify user experience metrics**
55. **Include load testing scenarios**
56. **Define security incident response**
57. **Specify change management procedures**
58. **Include knowledge transfer requirements**
59. **Define stakeholder communication procedures**
60. **Specify continuous improvement processes**

### Communication Patterns (61-80)

61. **Define signal communication protocols**
62. **Specify escalation procedures**
63. **Include stakeholder notification requirements**
64. **Define progress reporting frequency**
65. **Specify meeting cadence and requirements**
66. **Include documentation update procedures**
67. **Define cross-team coordination protocols**
68. **Specify vendor communication procedures**
69. **Include customer communication standards**
70. **Define incident communication protocols**
71. **Specify status update formats**
72. **Include decision documentation requirements**
73. **Define knowledge sharing procedures**
74. **Specify feedback collection methods**
75. **Include retrospective procedures**
76. **Define lessons learned documentation**
77. **Specify training and onboarding procedures**
78. **Include best practice documentation**
79. **Define standard operating procedures**
80. **Specify emergency communication protocols**

### Integration Requirements (81-100)

81. **Define third-party service integrations**
82. **Specify API versioning strategies**
83. **Include data migration procedures**
84. **Define system interface contracts**
85. **Specify message queuing requirements**
86. **Include event streaming procedures**
87. **Define service discovery mechanisms**
88. **Specify configuration synchronization**
89. **Include distributed tracing requirements**
90. **Define service mesh integration**
91. **Specify secret management procedures**
92. **Include identity federation requirements**
93. **Define multi-cloud integration**
94. **Specify edge computing requirements**
95. **Include IoT device integration**
96. **Define mobile app integration**
97. **Specify web hook procedures**
98. **Include file transfer protocols**
99. **Define database replication**
100. **Specify analytics integration**

### Advanced Settings (101+)

101. **Define AI model selection criteria**
102. **Specify prompt optimization strategies**
103. **Include machine learning integration**
104. **Define natural language processing requirements**
105. **Specify computer vision integration**
106. **Include predictive analytics requirements**
107. **Define automation workflows**
108. **Specify robotic process integration**
109. **Include blockchain requirements**
110. **Define quantum computing preparation**
111. **Specify edge AI requirements**
112. **Include federated learning procedures**
113. **Define ethical AI guidelines**
114. **Specify model monitoring procedures**
115. **Include AI governance requirements**

## üé® Prompt Templates and Examples

### Feature Implementation Template
```markdown
## Feature: [Feature Name]

**Objective**: [Clear, measurable objective]
**User Story**: As a [user type], I want [goal] so that [benefit]
**Acceptance Criteria**:
- [Criteria 1]
- [Criteria 2]
- [Criteria 3]

**Technical Requirements**:
- **Architecture**: [System design considerations]
- **API Endpoints**: [List of endpoints with methods]
- **Data Models**: [Database schemas and relationships]
- **Performance**: [Response time, throughput requirements]
- **Security**: [Authentication, authorization, validation]
- **Testing**: [Test types and coverage requirements]

**Implementation Approach**:
1. **Phase 1**: [First implementation milestone]
2. **Phase 2**: [Second implementation milestone]
3. **Phase 3**: [Final implementation milestone]

**Signal Sequence**:
- [tp] Test infrastructure ready
- [dp] Phase 1 implementation complete
- [dp] Phase 2 implementation complete
- [dp] Phase 3 implementation complete
- [tg] All tests passing
- [cq] Code quality validated
- [da] Ready for DoD assessment

**Dependencies**: [List of dependencies and prerequisites]
**Risks**: [Potential risks and mitigation strategies]
**Success Metrics**: [How success will be measured]
```

### Bug Fix Template
```markdown
## Bug Fix: [Bug Description]

**Issue**: [Clear description of the problem]
**Impact**: [How the issue affects users]
**Reproduction Steps**:
1. [Step 1]
2. [Step 2]
3. [Step 3]

**Expected Behavior**: [What should happen]
**Actual Behavior**: [What actually happens]

**Root Cause Analysis**:
- **Primary Cause**: [Main reason for the bug]
- **Contributing Factors**: [Other factors that contributed]
- **Affected Components**: [List of affected code/components]

**Fix Strategy**:
- **Solution**: [Description of the fix]
- **Testing Strategy**: [How to verify the fix]
- **Regression Tests**: [Tests to prevent similar issues]

**Implementation**:
- **Files to Change**: [List of files to modify]
- **Changes Required**: [Specific changes needed]
- **Backward Compatibility**: [Impact on existing functionality]

**Signal Usage**:
- [bf] Bug identified and root cause found
- [bf] Fix implemented and tested
- [br] Any blockers resolved during fix
- [da] Ready for validation

**Verification**:
- [ ] Bug reproduction confirmed
- [ ] Fix implemented successfully
- [ ] Regression tests pass
- [ ] No new issues introduced
- [ ] Performance impact assessed
```

### Refactoring Template
```markdown
## Refactoring: [Refactoring Description]

**Current State**: [Description of current implementation]
**Problems Identified**:
- [Problem 1]
- [Problem 2]
- [Problem 3]

**Proposed Solution**:
- **New Architecture**: [Description of improved architecture]
- **Benefits**: [List of benefits and improvements]
- **Migration Strategy**: [How to transition from current to new state]

**Refactoring Steps**:
1. **Preparation**: [Setup and preparation steps]
2. **Implementation**: [Core refactoring changes]
3. **Migration**: [Data/code migration procedures]
4. **Validation**: [Testing and verification steps]
5. **Cleanup**: [Removal of old code]

**Risk Mitigation**:
- **Rollback Plan**: [How to revert if issues occur]
- **Testing Strategy**: [Comprehensive testing approach]
- **Gradual Rollout**: [Phased implementation approach]

**Signal Usage**:
- [dp] Refactoring phase completed
- [bf] Any issues identified and resolved
- [br] Blockers removed during refactoring
- [cq] Code quality maintained/improved
- [da] Ready for final validation

**Success Criteria**:
- [ ] Performance improved by X%
- [ ] Code complexity reduced
- [ ] Maintainability improved
- [ ] No functionality regression
- [ ] Tests continue to pass
```

## üîç Prompt Quality Validation

### Self-Assessment Checklist

Before sending a prompt to an agent, validate:

**Clarity and Completeness**:
- [ ] Objective is clear and measurable
- [ ] All requirements are explicitly stated
- [ ] Constraints and limitations are defined
- [ ] Success criteria are specific and verifiable

**Technical Specifications**:
- [ ] Technical requirements are detailed
- [ ] Architecture and design considerations included
- [ ] Performance requirements specified
- [ ] Security and compliance requirements defined

**Signal Integration**:
- [ ] Signal sequences are clearly defined
- [ ] Signal comment standards are specified
- [ ] Escalation procedures are included
- [ ] Progress tracking requirements are defined

**Quality Standards**:
- [ ] Testing requirements are specified
- [ ] Code quality standards are defined
- [ ] Documentation requirements are included
- [ ] Validation procedures are outlined

**Risk Management**:
- [ ] Potential risks are identified
- [ ] Mitigation strategies are included
- [ ] Rollback procedures are defined
- [ ] Dependencies and prerequisites are listed

### Prompt Review Process

1. **Initial Draft**: Create comprehensive prompt following templates
2. **Self-Review**: Validate against checklist above
3. **Peer Review**: Have team member review for clarity and completeness
4. **Final Validation**: Ensure prompt meets all quality standards
5. **Execution**: Send to agent with clear expectations
6. **Monitoring**: Track progress through signals
7. **Adjustment**: Provide clarification or additional guidance as needed

## üéØ Common Prompting Pitfalls and Solutions

### Pitfall 1: Vague Requirements
**Problem**: "Improve the authentication system"
**Solution**: "Implement password reset functionality with email verification, token expiry in 1 hour, rate limiting of 3 requests per hour, and comprehensive logging"

### Pitfall 2: Missing Success Criteria
**Problem**: "Add caching to improve performance"
**Solution**: "Implement Redis caching for user profiles with 5-minute TTL, achieve 50% reduction in database queries, maintain cache consistency, and add cache hit rate monitoring"

### Pitfall 3: Ignoring Error Handling
**Problem**: "Create user registration endpoint"
**Solution**: "Create user registration endpoint with input validation, duplicate email detection, password strength requirements, verification email sending, and comprehensive error responses"

### Pitfall 4: No Testing Requirements
**Problem**: "Fix the login bug"
**Solution**: "Fix the login bug and add regression tests covering normal login, invalid credentials, expired tokens, and edge cases with 95% coverage"

### Pitfall 5: Missing Signal Instructions
**Problem**: "Implement the new feature"
**Solution**: "Implement the feature using this signal sequence: [tp] for test setup, [dp] for implementation milestones, [tg] for test completion, [cq] for quality validation, [da] for final assessment"

## üìö Resources and References

### Recommended Reading
- **"Prompt Engineering for Large Language Models"** - OpenAI Documentation
- **"System Design for Autonomous Agents"** - Academic Research Papers
- **"Software Engineering Best Practices"** - IEEE Standards
- **"AI Safety and Alignment"** - Research Publications

### Tools and Frameworks
- **OpenAI API**: GPT-4 and other models for agent implementation
- **Anthropic Claude**: Advanced reasoning and code generation
- **LangChain**: Framework for building agent applications
- **AutoGPT**: Autonomous agent implementation reference

### Communities and Forums
- **OpenAI Developer Forum**: Prompt engineering discussions
- **Anthropic Community**: Claude agent best practices
- **GitHub Discussions**: PRP implementation and experiences
- **Stack Overflow**: Technical implementation questions

### Case Studies and Examples
- **Autonomous Development Systems**: Real-world implementations
- **Multi-Agent Coordination**: Successful patterns and approaches
- **Signal-Driven Architecture**: Production deployments
- **Quality Automation**: Continuous integration and validation

---

## üéâ Conclusion

Mastering PRP prompting is essential for successful autonomous development. By following the principles, techniques, and templates in this guide, you can create prompts that enable AI agents to work autonomously for extended periods while maintaining high quality standards.

**Key Takeaways**:
1. **Clarity and Precision**: Specific, measurable requirements are essential
2. **Signal Integration**: Proper signal usage enables coordination and tracking
3. **Agent-Specific Approach**: Tailor prompts to each agent's expertise and personality
4. **Quality Focus**: Build in validation and testing requirements
5. **Continuous Improvement**: Learn from results and refine prompting techniques

As you gain experience with PRP prompting, you'll develop an intuition for what makes prompts effective and how to guide autonomous agents toward successful outcomes. Remember that prompting is both an art and a science - continuous learning and adaptation are key to mastery.

For implementation guidance, see the **User Guide**. For methodology background, see the **Theory Document**.